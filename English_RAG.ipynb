{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página web\n",
    "url = \"https://www.inspiredtaste.net/24593/essential-pancake-recipe/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer info y dividirla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_url(url):\n",
    "    #Conectarme a la página web y extraer la información\n",
    "    text_data = \"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text_data = \" \".join([p.text for p in soup.find_all('p')])\n",
    "        else:\n",
    "            print(f\"Error al acceder a la página, código de estado: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Se produjo un error durante la solicitud HTTP: {e}\")\n",
    "    \n",
    "    return text_data \n",
    "\n",
    "def dividir_texto(texto):\n",
    "    #Divide el texto en fragmentos manejables para la indexación.\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    return splitter.split_text(texto)\n",
    "\n",
    "\n",
    "def extraer_texto_y_dividir(url):\n",
    "    #Extrae el texto de una página web y lo divide en fragmentos.\n",
    "    texto = extraer_info_url(url)\n",
    "    if not texto:\n",
    "        print(\"El texto estaba vacío\")\n",
    "        texto = []\n",
    "    \n",
    "    return dividir_texto(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear embeddings y vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/miniconda3/envs/rag/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "chunks = extraer_texto_y_dividir(url)\n",
    "\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    collection_name=\"web_data\",\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./vectorstoreIngles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer consultas a Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")  \n",
    "\n",
    "def realizar_consulta(vectorstore, consulta):\n",
    "    #Realiza una consulta al vector store utilizando un modelo LLM.\n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "    respuesta = qa_chain.run(consulta)\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45458/3356404900.py:8: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  respuesta = qa_chain.run(consulta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: The main topic of the webpage appears to be a recipe blog called \"Inspired Taste\" that shares easy recipes, straightforward recipe videos, and cooking inspiration.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta\n",
    "consulta = \"What is the main topic of the webpage?\"\n",
    "if vectorstore:\n",
    "    respuesta = realizar_consulta(vectorstore, consulta)\n",
    "    print(f\"Respuesta: {respuesta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de búsqueda\n",
    "def search_chroma(query, top_k):\n",
    "    try:\n",
    "        respuesta = realizar_consulta(vectorstore, query)  # Aquí asumes que `realizar_consulta` está definida\n",
    "        return respuesta\n",
    "    except Exception as e:\n",
    "        return f\"Error en la búsqueda: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfaz gráfica GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/miniconda3/envs/rag/lib/python3.13/site-packages/gradio/blocks.py:1048: UserWarning: Cannot load huggingface. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/huggingface (Request ID: Root=1-67606e61-2093277e463765b23021bca8;e764bfec-9ffb-447e-92b8-0cd057cf54a5)\n",
      "\n",
      "Sorry, we can't find the page you are looking for.\n",
      "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* Running on public URL: https://2e472d852fcf872608.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2e472d852fcf872608.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interfaz\n",
    "with gr.Blocks(theme=\"huggingface\") as demo:\n",
    "    # Título y descripción\n",
    "    gr.Markdown(\"\"\"\n",
    "        # RAG Search Application\n",
    "        This app allows you to query a vector store based on content extracted from a webpage.\n",
    "        Enter your query below and select the number of results you'd like to see.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query_input = gr.Textbox(label=\"Enter Your Query\", placeholder=\"Type your question here...\", elem_id=\"query-box\")\n",
    "        top_k_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Results\")\n",
    "\n",
    "    # Botón de búsqueda con diseño personalizado\n",
    "    with gr.Row():\n",
    "        search_button = gr.Button(\"Search\", elem_id=\"search-button\", variant=\"primary\")\n",
    "    \n",
    "    # Resultados con formato mejorado\n",
    "    output_box = gr.Textbox(label=\"Search Results\", lines=15, elem_id=\"results-box\")\n",
    "\n",
    "    # Mostrar mensaje de carga mientras se procesa la consulta\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#### Example Queries:\")\n",
    "        gr.Markdown(\"\"\"\n",
    "            - How to make the best homemade pancake?\n",
    "            - Tell me the ingredients of the recipe.\n",
    "        \"\"\")\n",
    "\n",
    "    # Asociar la función de búsqueda con el botón\n",
    "    search_button.click(fn=search_chroma, inputs=[query_input, top_k_input], outputs=output_box)\n",
    "    \n",
    "    # Agregar una acción de \"limpiar\" para el campo de resultados\n",
    "    clear_button = gr.Button(\"Clear\", elem_id=\"clear-button\")\n",
    "    clear_button.click(lambda: \"\", None, output_box)\n",
    "\n",
    "# Lanzar la interfaz\n",
    "demo.launch(debug=False, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
